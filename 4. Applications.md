# Why MPC?

And this brings us back round to a key question posed from the beginning. _When do I need MPC?_ We know of the utility of Zero Knowledge Proofs (ZKP) as a means for proving calculations to a network, but "arbitrary" MPC when you only have the most basic of primitives, that being addition and multiplication, simply isn't as useful to a developer. 

MPC, in this form, does not lead to an increase in compute via distributed computing, it in fact consumes more compute to perform basic tasks so that it adheres to the privacy preservation that secret sharing calls for. 

Secret sharing to begin with is already a concept that has fairly fringe use cases and as such, hasn't found mainstream use at all. Even [papers looking into their applications](https://www.sciencedirect.com/science/article/pii/S1574013723000758) can at most list off _theoretical_ implementations for IoT, cloud storage and perhaps federated learning, but it still hasn't been put into practice for reasons we've repeatedly discussed.

ZKPs are a subset of MPC that have far more immediate applications and use-cases and doesn't share the same overarching complexity that MPC _via secret sharing (!!)_ does. 

But maybe I'm just not thinking far ahead enough, so let's look at visionaries which supposedly have.
# A Look at Projects Using Nillion

Nillion does feature a set of open source projects which have been built using Nillion so that we can get a feel for how we can actually apply secret sharing and MPC.

## Federated Learning with Nillion

Federated learning is a big deal. Essentially, it's the training of large deep learning models in a distributed, decentralized manner. This is not to be confused with _distributed learning_, which does this to parallelize computing power. Federated learning aims to train a model with multiple local datasets that each participant owns, then shares the model that it trains to some centralized authority to create a global AI model. The assumption is that you can create a global model from all these local models as the datasets should be largely heterogeneous.

Data privacy then becomes a concern as participants are meant to train models with their own private local datasets that do not need to be known by other participants, yet they still have to share and aggregate the trained models that their datasets produce.

[This project](https://github.com/bowenyou/nillion-federated-learning) shows an example of how this can be achieved. Essentially, all participants train a model locally, then secret share their weights and perform a blind computation to average the weights to produce the global model. 

However, there are pretty glaring limitations:
- The number of parties that can participate is limited
- The size of the models and the type of models are limited
- More complex weight aggregation methods besides averaging are limited

This all comes down to the lack of scalability such a system possesses. To secret share millions of weights across multiple participants and perform a complex blind computation on all those weights is simply unviable, and in its current state, Nillion simply errors out when subject to such a hefty computation. 

The model demoed here is [extremely small and simple](https://github.com/bowenyou/nillion-federated-learning/blob/main/client_nfl/model.py) (we're looking at only 67 trainable weights for a model training on the Iris classification dataset), which is expected as anything larger would probably kill the local test net. Is this a problem that can be solved with a live network with multiple nodes? Maybe, maybe not.

We have a similar use case in [this project](https://github.com/csalvador58/ethglobal_nillion_health), which applies this to the computation of a healthcare imaging diagnosis model, and we face similar limitations here.
## Meeting Scheduling

[This project](https://github.com/kanav99/privycal) calculates the intersection of all parties' calendars to find a common meeting time without having to reveal your whole schedule to the other party. Sounds good. It's a frequently conducted task with a simple underlying basis that can be translated into the primitives that Nillion offers.

The main limitation that sticks out is the fact that you can only schedule meetings 1 day in advanced as once again, to compute anything more would lead to an error out. 

From a developer's perspective, the work required to implement what is otherwise a fairly basic task is non-negligible, and limitations brought about by multiplicative blinding (such as the condition that we cannot introduce zero as an input value as it may break multiplication and leak other secrets) does mean that you have to whack workarounds for otherwise simple tasks.

## Decentralized Email Marketing...?

[This project](https://github.com/ysongh/EmailEon) is pretty confusing. It says it uses Nillion to "encrypt email addresses with access control limited to the company and user", so I'm assuming it mainly uses the secret-storing part of Nillion and not the MPC part. The vast majority of the code seems to involve the use of [Mailchain](https://mailchain.com/), some Web3 native way of sending emails.

Giving the code a cursory look, it looks like that this is a means to send emails to subscribers to marketing schemes, and I assume the privacy enhancement part is performing... blind emails? So you send the emails out without knowing who you're sending them out to? The source code, frankly, is a mess to read through, and with little documentation to work with, it's hard to give this project a thorough evaluation.


# Concluding Remarks

Nillion, for all intents and purposes, introduces something that is technically impressive and holds true to their claims of enabling MPC and secret sharing. However, with only primitives to work with and a fairly opaque network structure that does not seem to nicely translate the principles of secret sharing, it makes it a bit questionable as to whether developers really need a system like Nillion when the limitations that such a flavour of MPC brings about far outweighs most practical applications. Even if Nada has an RNG (which it currently doesn't have) and offers "MPC secret-shared provable random numbers", why would, say, a gambling service, use Nillion to perform provable RNG when it can already be achieved in a far easier manner using ZKPs?

Overall, Nillion isn't a nothingburger in the sense that their tech is vapourwave. In fact, by even having a novel MPC scheme that is mathematically sound, that's already brought more to the table than a lot of other projects in the space. However, I just can't seem to find practical uses for MPC in a state like this, nor can I think of uses for secret sharing. From a technical standpoint, Nillion is really cool! But as a developer? I don't think I'd be using it.
